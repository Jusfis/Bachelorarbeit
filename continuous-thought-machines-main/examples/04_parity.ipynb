{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04a72c0e",
   "metadata": {},
   "source": [
    "# The Continuous Thought Machine – Tutorial 04: Parity [![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/SakanaAI/continuous-thought-machines/blob/main/examples/04_parity.ipynb) [![arXiv](https://img.shields.io/badge/arXiv-2505.05522-b31b1b.svg)](https://arxiv.org/abs/2505.05522)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05cf27b",
   "metadata": {},
   "source": [
    "### Parity\n",
    "\n",
    "The parity of a binary sequence, given by the sign of the product of its elements, can reasonably be predicted by an RNN when the data is fed sequentially - the model need only maintain an internal state, flipping a ‘switch’ whenever a negative number is encountered. When the entire sequence is provided at once, however, the task is significantly more challenging.\n",
    "\n",
    "In Section 8 of the [technical report](https://arxiv.org/pdf/2505.05522), we showcase how a CTM can be trained to do exactly this. In particular, we input the CTM with a binary sequence, and train the model to predict the cumulative parity at each position along the sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbffa93",
   "metadata": {},
   "source": [
    "### Tutorial Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c2bbea",
   "metadata": {},
   "source": [
    "In this tutorial, we walk through how we trained the CTM, using sequences of length 16."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2272f18",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c257dbd3",
   "metadata": {},
   "source": [
    "In addition to installing some dependencies, we also clone the CTM repo (assuming this tutorial is being run in Colab), so that we can access the base CTM model."
   ]
  },
  {
   "cell_type": "code",
   "id": "5c06d1e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T13:21:36.348305Z",
     "start_time": "2025-12-12T13:21:36.345721Z"
    }
   },
   "source": "USE_COLAB = False",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "30ab5f0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T13:21:40.494589Z",
     "start_time": "2025-12-12T13:21:40.492124Z"
    }
   },
   "source": [
    "import sys\n",
    "\n",
    "if USE_COLAB:\n",
    "    !git clone https://github.com/SakanaAI/continuous-thought-machines.git\n",
    "    sys.path.append(\"./continuous-thought-machines\")\n",
    "else:\n",
    "    sys.path.append(\"..\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "c1ccfdcf",
   "metadata": {},
   "source": [
    "!pip install gdown\n",
    "!pip install mediapy"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1ab57a96",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "id": "24ffe416",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T13:21:47.702827Z",
     "start_time": "2025-12-12T13:21:44.325730Z"
    }
   },
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "import imageio\n",
    "import mediapy\n",
    "\n",
    "# From CTM repo\n",
    "from models.ctm_kan import ContinuousThoughtMachine as CTM\n",
    "from tasks.parity.plotting import make_parity_gif\n",
    "from tasks.parity.utils import reshape_attention_weights, reshape_inputs"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "id": "82620e4e",
   "metadata": {},
   "source": [
    "Set a seed for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "id": "604415b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T13:21:55.481700Z",
     "start_time": "2025-12-12T13:21:55.477547Z"
    }
   },
   "source": [
    "def set_seed(seed=42, deterministic=True):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = deterministic\n",
    "    torch.backends.cudnn.benchmark = False"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "b2ba7f7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T13:21:56.667452Z",
     "start_time": "2025-12-12T13:21:56.657561Z"
    }
   },
   "source": [
    "set_seed(42)"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "4407a4a8",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e271bc4c",
   "metadata": {},
   "source": [
    "We define a dataset to create the parity sequences for training and testing. Each sample is a sequence of length `sequence_length`, where we randomly place -1s and 1s at each position. We calculate the target sequence (of the same length) as the parity upto and including that position, with 0s corresponding to negative parity and 1s corrsponding to positive parity."
   ]
  },
  {
   "cell_type": "code",
   "id": "830313fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T13:22:02.630758Z",
     "start_time": "2025-12-12T13:22:02.625784Z"
    }
   },
   "source": [
    "class ParityDataset(Dataset):\n",
    "    def __init__(self, sequence_length=64, length=100000):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.length = length\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        vector = 2 * torch.randint(0, 2, (self.sequence_length,)) - 1\n",
    "        vector = vector.float()\n",
    "        negatives = (vector == -1).to(torch.long)\n",
    "        cumsum = torch.cumsum(negatives, dim=0)\n",
    "        target = (cumsum % 2 != 0).to(torch.long)\n",
    "        return vector, target"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "39ec4d00",
   "metadata": {},
   "source": [
    "We set the parity sequence length to `grid_size ** 2 = 16`, and prepare the train and test loaders. We use a `batch_size` of 64."
   ]
  },
  {
   "cell_type": "code",
   "id": "cc28def0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T13:25:31.981434Z",
     "start_time": "2025-12-12T13:25:31.975680Z"
    }
   },
   "source": [
    "grid_size = 4\n",
    "parity_sequence_length = grid_size ** 2\n",
    "\n",
    "train_data = ParityDataset(sequence_length=parity_sequence_length, length=100000)\n",
    "test_data = ParityDataset(sequence_length=parity_sequence_length, length=10000)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=5, shuffle=True, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=5, shuffle=True, num_workers=0, drop_last=False)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "e94a149b",
   "metadata": {},
   "source": [
    "We can visualise what these inputs and targets look like. White squares correspond to positive parity, and black squares correspond to negative parity."
   ]
  },
  {
   "cell_type": "code",
   "id": "33503097",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T13:25:33.620787Z",
     "start_time": "2025-12-12T13:25:33.528146Z"
    }
   },
   "source": [
    "%matplotlib inline\n",
    "sample_inputs, sample_targets = next(iter(trainloader))\n",
    "sample_input = sample_inputs[0,:].reshape(grid_size, grid_size)\n",
    "sample_target = sample_targets[0,:].reshape(grid_size, grid_size)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(6, 3))\n",
    "\n",
    "# Plot the input\n",
    "ax1.imshow(sample_input.flip(0), cmap='gray')\n",
    "for i in range(grid_size+1):\n",
    "    ax1.axhline(i-0.5, color='black', linewidth=2,)\n",
    "    ax1.axvline(i-0.5, color='black', linewidth=2)\n",
    "ax1.set_xlim(-0.5, grid_size-0.5)\n",
    "ax1.set_ylim(-0.5, grid_size-0.5)\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticks([])\n",
    "ax1.set_title('Input')\n",
    "\n",
    "# Plot the target\n",
    "ax2.imshow(sample_target.flip(0), cmap='gray')\n",
    "for i in range(grid_size+1):\n",
    "    ax2.axhline(i-0.5, color='black', linewidth=2)\n",
    "    ax2.axvline(i-0.5, color='black', linewidth=2)\n",
    "ax2.set_xlim(-0.5, grid_size-0.5)\n",
    "ax2.set_ylim(-0.5, grid_size-0.5)\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticks([])\n",
    "ax2.set_title('Target')\n",
    "\n",
    "plt.tight_layout()\n",
    "print(f\"Input: {sample_inputs[0].tolist()}\")\n",
    "print(f\"Target: {sample_targets[0].tolist()}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [-1.0, 1.0, -1.0, -1.0, -1.0, 1.0, -1.0, -1.0, -1.0, -1.0, 1.0, -1.0, 1.0, 1.0, 1.0, -1.0]\n",
      "Target: [1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 600x300 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "069121b9",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d91d78",
   "metadata": {},
   "source": [
    "Next we define the loss function. First, for all internal ticks of the CTM, we calculate the cross-entropy loss for all positions along the output sequence. Then, as with the other experiments, we only use the loss at two specific internal ticks: where the loss is the lowest and where the model is most certain. We use advanced indexing into the losses tensor to extract these losses, and then average them."
   ]
  },
  {
   "cell_type": "code",
   "id": "63e75f71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T13:25:42.949070Z",
     "start_time": "2025-12-12T13:25:42.946024Z"
    }
   },
   "source": [
    "def parity_loss(predictions, certainties, targets, use_most_certain=True):\n",
    "    \"\"\"\n",
    "    Computes the parity loss.\n",
    "\n",
    "    Predictions are of shape: (B, parity_sequence_length, class, internal_ticks),\n",
    "        where classes are in [0,1,2,3,4] for [Up, Down, Left, Right, Wait]\n",
    "    Certainties are of shape: (B, 2, internal_ticks), \n",
    "        where the inside dimension (2) is [normalised_entropy, 1-normalised_entropy]\n",
    "    Targets are of shape: [B, parity_sequence_length]\n",
    "\n",
    "    use_most_certain will select either the most certain point or the final point. For baselines,\n",
    "        the final point proved the only usable option. \n",
    "    \"\"\"\n",
    "\n",
    "    # Losses are of shape [B, parity_sequence_length, internal_ticks]\n",
    "    losses = nn.CrossEntropyLoss(reduction='none')(predictions.flatten(0,1), torch.repeat_interleave(targets.unsqueeze(-1), predictions.size(-1), -1).flatten(0,1).long()).reshape(predictions[:,:,0].shape)\n",
    "\n",
    "    # Average the loss over the parity sequence dimension\n",
    "    losses = losses.mean(1)\n",
    "\n",
    "    loss_index_1 = losses.argmin(dim=1)\n",
    "    loss_index_2 = certainties[:,1].argmax(-1)\n",
    "    if not use_most_certain:\n",
    "        loss_index_2[:] = -1\n",
    "    \n",
    "    batch_indexer = torch.arange(predictions.size(0), device=predictions.device)\n",
    "    loss_minimum_ce = losses[batch_indexer, loss_index_1].mean()\n",
    "    loss_selected = losses[batch_indexer, loss_index_2].mean()\n",
    "\n",
    "    loss = (loss_minimum_ce + loss_selected)/2\n",
    "    return loss, loss_index_2"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "a712a9a9",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cb8dd7",
   "metadata": {},
   "source": [
    "We define some helper functions for making the progress bar look pretty, and to display the training curves."
   ]
  },
  {
   "cell_type": "code",
   "id": "fb57caee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T13:25:45.300102Z",
     "start_time": "2025-12-12T13:25:45.294786Z"
    }
   },
   "source": [
    "def make_pbar_desc(train_loss, train_accuracy, test_loss, test_accuracy, lr, where_most_certain):\n",
    "    \"\"\"A helper function to create a description for the tqdm progress bar\"\"\"\n",
    "    pbar_desc = f'Train Loss={train_loss:0.3f}. Train Acc={train_accuracy:0.3f}. Test Loss={test_loss:0.3f}. Test Acc={test_accuracy:0.3f}. LR={lr:0.6f}.'\n",
    "    pbar_desc += f' Where_certain={where_most_certain.float().mean().item():0.2f}+-{where_most_certain.float().std().item():0.2f} ({where_most_certain.min().item():d}<->{where_most_certain.max().item():d}).'\n",
    "    return pbar_desc"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "19208f41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-12T13:25:47.392695Z",
     "start_time": "2025-12-12T13:25:47.386763Z"
    }
   },
   "source": [
    "def update_training_curve_plot(fig, ax1, ax2, train_losses, test_losses, train_accuracies, test_accuracies, steps):\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    # Plot loss\n",
    "    ax1.clear()\n",
    "    ax1.plot(range(len(train_losses)), train_losses, 'b-', alpha=0.7, label=f'Train Loss: {train_losses[-1]:.3f}')\n",
    "    ax1.plot(steps, test_losses, 'r-', marker='o', label=f'Test Loss: {test_losses[-1]:.3f}')\n",
    "    ax1.set_title('Loss')\n",
    "    ax1.set_xlabel('Step')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "\n",
    "    # Plot accuracy\n",
    "    ax2.clear()\n",
    "    ax2.plot(range(len(train_accuracies)), train_accuracies, 'b-', alpha=0.7, label=f'Train Accuracy: {train_accuracies[-1]:.3f}')\n",
    "    ax2.plot(steps, test_accuracies, 'r-', marker='o', label=f'Test Accuracy: {test_accuracies[-1]:.3f}')\n",
    "    ax2.set_title('Accuracy')\n",
    "    ax2.set_xlabel('Step')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    display(fig)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "71541842",
   "metadata": {},
   "source": [
    "We then write the function to train the CTM."
   ]
  },
  {
   "cell_type": "code",
   "id": "02de7c62",
   "metadata": {},
   "source": [
    "def train(model, trainloader, testloader, device='cpu', training_iterations=10000, test_every=1000, lr=1e-4, log_dir='./logs'):\n",
    "\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "    \n",
    "    model.train()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    iterator = iter(trainloader)\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    steps = []\n",
    "    \n",
    "    plt.ion()\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "    with tqdm(total=training_iterations) as pbar:\n",
    "        for stepi in range(training_iterations):\n",
    "\n",
    "            try:\n",
    "                inputs, targets = next(iterator)\n",
    "            except StopIteration:\n",
    "                iterator = iter(trainloader)\n",
    "                inputs, targets = next(iterator)\n",
    "    \n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            predictions_raw, certainties, _ = model(inputs)\n",
    "\n",
    "            # Reshape: (B, SeqLength, C, T)\n",
    "            predictions = predictions_raw.reshape(predictions_raw.size(0), -1, 2, predictions_raw.size(-1))\n",
    "            \n",
    "            # Compute loss\n",
    "            train_loss, where_most_certain = parity_loss(predictions, certainties, targets, use_most_certain=True)\n",
    "            train_accuracy = (predictions.argmax(2)[torch.arange(predictions.size(0), device=predictions.device), :, where_most_certain] == targets).float().mean().item()\n",
    "\n",
    "            train_losses.append(train_loss.item())\n",
    "            train_accuracies.append(train_accuracy)\n",
    "\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if stepi % test_every == 0 or stepi == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    all_test_predictions = []\n",
    "                    all_test_targets = []\n",
    "                    all_test_where_most_certain = []\n",
    "                    all_test_losses = []\n",
    "\n",
    "                    for inputs, targets in testloader:\n",
    "                        inputs = inputs.to(device)\n",
    "                        targets = targets.to(device)\n",
    "                        \n",
    "                        predictions_raw, certainties, where_most_certain = model(inputs)\n",
    "                        predictions = predictions_raw.reshape(predictions_raw.size(0), -1, 2, predictions_raw.size(-1))\n",
    "                        \n",
    "                        test_loss, where_most_certain = parity_loss(predictions, certainties, targets, use_most_certain=True)\n",
    "                        all_test_losses.append(test_loss.item())\n",
    "                        all_test_predictions.append(predictions)\n",
    "                        all_test_targets.append(targets)\n",
    "                        all_test_where_most_certain.append(where_most_certain)\n",
    "\n",
    "                    all_test_predictions = torch.cat(all_test_predictions, dim=0)\n",
    "                    all_test_targets = torch.cat(all_test_targets, dim=0)\n",
    "                    all_test_where_most_certain = torch.cat(all_test_where_most_certain, dim=0)\n",
    "\n",
    "                    test_accuracy = (all_test_predictions.argmax(2)[torch.arange(all_test_predictions.size(0), device=predictions.device), :, all_test_where_most_certain] == all_test_targets).float().mean().item()\n",
    "                    test_loss = sum(all_test_losses) / len(all_test_losses)\n",
    "\n",
    "                    test_losses.append(test_loss)\n",
    "                    test_accuracies.append(test_accuracy)\n",
    "                    steps.append(stepi)\n",
    "\n",
    "                    # create_maze_gif_visualization(model, testloader, device, log_dir)\n",
    "\n",
    "                model.train()\n",
    "\n",
    "                update_training_curve_plot(fig, ax1, ax2, train_losses, test_losses, train_accuracies, test_accuracies, steps)\n",
    "\n",
    "            pbar_desc = make_pbar_desc(train_loss=train_loss.item(), train_accuracy=train_accuracy, test_loss=test_loss, test_accuracy=test_accuracy, lr=optimizer.param_groups[-1][\"lr\"], where_most_certain=where_most_certain)\n",
    "            pbar.set_description(pbar_desc)\n",
    "            pbar.update(1)\n",
    "\n",
    "    plt.ioff()\n",
    "    plt.close(fig)\n",
    "    return model\n",
    "\n",
    "def create_maze_gif_visualization(model, testloader, device, log_dir):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        inputs_viz, targets_viz = next(iter(testloader))\n",
    "        inputs_viz = inputs_viz.to(device)\n",
    "        targets_viz = targets_viz.to(device)\n",
    "\n",
    "        predictions_raw, certainties, _, pre_activations, post_activations, attention = model(inputs_viz, track=True)\n",
    "        \n",
    "        # Reshape predictions\n",
    "        predictions = predictions_raw.reshape(predictions_raw.size(0), -1, 2, predictions_raw.size(-1))\n",
    "        \n",
    "        attention = reshape_attention_weights(attention)\n",
    "        inputs = reshape_inputs(inputs_viz, 50, grid_size=grid_size)\n",
    "\n",
    "        # Generate the parity GIF\n",
    "        make_parity_gif(\n",
    "            predictions.detach().cpu().numpy(),\n",
    "            certainties.detach().cpu().numpy(),\n",
    "            targets_viz.detach().cpu().numpy(),\n",
    "            pre_activations,\n",
    "            post_activations,\n",
    "            attention,\n",
    "            inputs,\n",
    "            f'{log_dir}/prediction.gif',\n",
    "        )\n",
    "        \n",
    "        predictions_raw, certainties, _ = model(inputs_viz)\n",
    "        predictions = predictions_raw.reshape(predictions_raw.size(0), -1, 2, predictions_raw.size(-1))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "67e6c8fc",
   "metadata": {},
   "source": [
    "### Initialzing the CTM "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9cac52",
   "metadata": {},
   "source": [
    "Next we initialize the CTM. There are three important arguments to highlight for this task, which differ from, for example, the image classification task.\n",
    "\n",
    "- `backbone_type = 'parity_backbone'`: the backbone type `'parity_backbone'`, which is defined in the CTM repo, is a learned embedding layer which embeds the binary values in the input sequence.\n",
    "- `positional_embedding_type = 'custom-rotational-1d'`: a positional embedding for each position in the parity sequence. These positional embeddings are added to the embedding vectors (produced by the backbone) during the forward pass.\n",
    "- `prediction_reshaper = [parity_sequence_length, 2]`: the CTM has an optional argument `prediction_reshaper`. This is required when the output of the model is a sequence. For instance, it is required here where the output is a sequence of parities, or in the maze task where the output is a sequence of actions. This prediction reshaper is used in each internal tick of the CTM when the certainty of the models output is computed. Generally, the prediction reshaper should be like `[SEQUENCE_LENGTH, NUM_CLASS]`."
   ]
  },
  {
   "cell_type": "code",
   "id": "2c180995",
   "metadata": {},
   "source": [
    "# Set device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Define the model\n",
    "model = CTM(\n",
    "    # iterations = 5,\n",
    "    # d_model = 32,\n",
    "    # d_input = 32,\n",
    "    # heads = 8,\n",
    "    # n_synch_out = 16,\n",
    "    # n_synch_action = 16,\n",
    "    # synapse_depth = 8,\n",
    "    # memory_length = 5,\n",
    "    # deep_nlms = False, # TRUE does;nt work\n",
    "    # memory_hidden_dims = 16,\n",
    "    # backbone_type = 'parity_backbone',\n",
    "    # out_dims = parity_sequence_length * 2,\n",
    "    # prediction_reshaper = [parity_sequence_length, 2],\n",
    "    # dropout = 0.0,\n",
    "    # do_layernorm_nlm = False,\n",
    "    # positional_embedding_type = 'custom-rotational-1d'\n",
    "    iterations = 50,\n",
    "    d_model = 256,\n",
    "    d_input = 32,\n",
    "    heads = 8,\n",
    "    n_synch_out = 256,\n",
    "    n_synch_action = 256,\n",
    "    synapse_depth = 8,\n",
    "    memory_length = 25,\n",
    "    deep_nlms = True,\n",
    "    memory_hidden_dims = 16,\n",
    "    backbone_type = 'parity_backbone',\n",
    "    out_dims = parity_sequence_length * 2,\n",
    "    prediction_reshaper = [parity_sequence_length, 2],\n",
    "    dropout = 0.0,\n",
    "    do_layernorm_nlm = False,\n",
    "    positional_embedding_type = 'custom-rotational-1d'\n",
    "\n",
    ").to(device)\n",
    "\n",
    "# Initialize model parameters with dummy forward pass\n",
    "sample_batch = next(iter(trainloader))\n",
    "dummy_input = sample_batch[0][:1].to(device)\n",
    "# dummy_input\n",
    "with torch.no_grad():\n",
    "    _ = model(dummy_input)\n",
    "\n",
    "print(f'Model parameters: {sum(p.numel() for p in model.parameters()):,}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a89daf13",
   "metadata": {},
   "source": "model = train(model=model, trainloader=trainloader, testloader=testloader, device=device, training_iterations=100, lr=1e-4, log_dir='./parity_logs')",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ca9cbd9b",
   "metadata": {},
   "source": [
    "Visualise a gif of a solution"
   ]
  },
  {
   "cell_type": "code",
   "id": "6ba0b9e4",
   "metadata": {},
   "source": [
    "reader = imageio.get_reader(\"parity_logs/prediction.gif\")\n",
    "frames = [reader.get_data(i) for i in range(min(len(reader), 100))]\n",
    "mediapy.show_video(frames, width=400, codec=\"gif\")"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
